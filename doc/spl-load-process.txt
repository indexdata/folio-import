Spokane Public Library data conversion and loading process

Data files are located in the hz-okapi project under the assets directory.
These files come in different formats: .mrc .json and a Horizon flavor of
JSON that is usual broken.

1.  Load all settings (ref data) if needed.  Currently locations, service-points, etc.
    get saved off as a previous system's settings and loaded into a new system.

2.  Instances (and SRS):

    a.  Concatenate the group*.mrc files into a single large file.
            ex: cat group*.mrc >> large-file.mrc

    b.  Convert large marc file to utf8.
            ex: yaz-marcdump -f marc8 -t utf8 -o marc -l 9=97 large-file.mrc > utf8.mrc

    NOTE: The marc files do not have the record ID in the 001 but mostly the 035.
    We need to run a script to "fix" this file by moving the record ID to the 001.

    c.  Fix the utf8 encoded marc file by running /perl/marc_ctrl_fix.pl

    d.  Download inventory reference data by running ./reference_inventory.sh (in /bash)

    e.  Run /perl/marc2inst.pl to create instances and SRS records.
            You will need to have a local copy of the FOLIO mapping rules
            and inventory reference data to run the above script. The script
            creates JSONL files for instances and SRS.  It will also create a
            snapshot object and instances map file (previous system ID to FOLIO uuid)

    f.  Use loadInventorySyncJSONL.js to load instances.
            ex: node loadInventorySyncJSONL.js data/instances.jsonl

    g.  Run loadJSONL.js to add snapshot.jsonl.
            ex: node loadJSONL.js source-storage/snapshots data/snapshot.jsonl

    h.  Load SRS objects.
            ex: node loadJSONL.js source-storage/records data/srs.jsonl

    NOTE: When loading instances and SRS, it may be a good idea to run several processes
    at the same time.  Use the Unix split command on the jsonl file.  This will create many 
    smaller files.  There is a script called run_inventory.sh that will run a
    background process for every file in a glob.
            ex: ./run_inventory.sh data/xa*

    Likewise, there is the run_load_jsonl.sh script that will load several jsonl files as a
    background process.

2. Holdings and items:

    a.  As above, concatenate the hz-holdings-*.json files into one large file.

    b.  There needs to be a collection.tsv file located in the same directory as
    as the reference data (previously downloaded).  There is a collections.json file
    located in the assets directory.  This file needs to be converted to TSV first by
    using jq.

        ex: jq -r '.mtypes[] | .code + "\t" + .name' collections.json > /refdir/collections.tsv

    c.  Run /perl/items_spl.pl to convert the Horizon holdings to Folio holdings and items.
            ex: ./items_spl.pl /refdir/ large-holdings.json file.

    d.  Load with loadInventorySyncStream.js (or convert the holdings and items files to
        JSONL format and use the multi-process runner ./run_inventory.sh).
        NOTE: The holdings and items files may be split using the splitLargeJson.js script

3.  Users:

    a.  Concatenate hz-users-*.json files to create one large users file.
    
    b.  Get groups.json from FOLIO and save it to the same directory as the large hz-users file.
            ex:  node downloadAllByEndpoint.js groups ../spl_data/users/

    c.  Run splUsers.js script (located in the /patron directory).  This process
        will create users files in addition to permissions and logins collections.

    d.  Now run loadByEndpoint.js on users.json files.  Perhaps all of these users files
        could be concatenated into several larger ones and the use the run_load_endpoint.sh 
        and run 5 or 10 jobs in the background.

4.  Loans:

    a.  Loans data from Spokane are located in the assets directory as hz-loans-(whatever).  Concatenate
        all loans objects into one loans.json files using jq.

        ex: jq '[.[]]' hz-loans-\(* > working_dir/loans.json

    b.  First download all users from FOLIO using the downloadAllUsers.js script.
        
        ex: node downloadAllUsers.js <working_directory>

    c.  Get service points with downloadAllByEndpoint.js

        ex: node downloadAllByEndpoint.js service-points <working_directory>

    d.  Run createSplCheckout.js in the /patrons/ directory.

        ex: node createSplCheckout.js <working_dir>/service-points.json <working_dir>/users.json <working_dir>/spokane/circ/loans.json

        The output from this script will create three files:
        
                * checkouts.json (load this file)
                * inactive_checkouts.json (user for active toggle)
                * notfound_checkouts.json (do not load-- users are not found for these checkouts)

    e.  The checkouts.json file contains loans for active and inactive users.  FOLIO doesn't allow checkouts to
        to inactive users, so these need to be made temporarily active.  Run usersActiveToggle.js to do this.

        ex: node usersActiveToggle.js <working_dir>/inactive_checkouts.json

    f.  Use the checkoutByBarcode.js script on the checkouts.json file.

        ex: node checkoutByBarcode.js <working_dir>/checkouts.json

    g.  Run usersActiveToggle.js again to reset inactive users to inactive.

5.  Requests:

    Requests are stored in the /assets/ directory as hz-requests.json.

    a.  Run splRequests.js to create FOLIO requests objects.

        ex: node splRequests <working_dir>/hz-requests.json

        This script will contact FOLIO to check the status of certain items.  It will also
        try to place requests on items in a round robin fashion, first checking for available items,
        then items with the least amount of holds.  This process will take some time to run.

        NOTE: Do not run multiple processes while during this step.

    b.  Use loadRequests.js to load the output from the previous process.
        
        ex: node loadRequests.js <working_dir>/requests.json

        NOTE: These request objects need to be run in order.  Please run a single process.

6.  Fines: (TODO)

    Fines are located in the /assets/ directory as hz-ledger.json 

7.  Organizations: (TODO)

    There is an old file in /assets/ named organizations-2020-12-01.json.  This looks Like
    a collection of FOLIO organization objects.  I don't know if there is anything to do except load?

8.  Orders: (TODO)

    There is an orders.py script here: https://gitlab.com/spokanepubliclibrary/hz-okapi/-/blob/master/scripts/orders.py 
    Perhaps this does something?

9.  Invoices (TODO)


     

    
